<!-- ![test](https://raw.githubusercontent.com/imdonnie/playground/master/Markdown-Images/GitHub个人首页.png) -->

#

<!-- TOC -->

- [1. 技术栈和架构简介](#1-技术栈和架构简介)
- [2. 文档内容](#2-文档内容)
- [3. Flask和接口调试](#3-flask和接口调试)
    - [3.1. 快速开始](#31-快速开始)
    - [3.2. 路由绑定](#32-路由绑定)
    - [3.3. 数据交互](#33-数据交互)
    - [3.4. 接口调试](#34-接口调试)
- [4. Cassandra数据库](#4-cassandra数据库)
    - [4.1. 未完成](#41-未完成)
- [5. Docker学习和使用](#5-docker学习和使用)
    - [5.1. 概念理解](#51-概念理解)
    - [5.2. Dockerfile和Container](#52-dockerfile和container)
    - [5.3. 更多Container操作和集群配置](#53-更多container操作和集群配置)
    - [5.4. 容器编排](#54-容器编排)
    - [5.5. 在Docker中调试](#55-在docker中调试)

<!-- /TOC -->

# 1. 技术栈和架构简介

# 2. 文档内容

# 3. Flask和接口调试

## 3.1. 快速开始

首先，从项目中最直观的部分开始，也就是Flask的安装和配置。[Flask项目的官网](flask.pocco.org)已经对安装和配置做了很详细的说明。如果真的遇到什么问题，网上关于Flask的教程也很丰富。因此只要Python环境没什么问题，Flask很快就可以安装完成，基本上安装就是几行命令就ok了，当然速度不一定很快。官网给出的安装命令如下：

```Shell
$ pip install flask
 * flask is installed
```

这里的hello.py在官网上也给出了[源代码](http://flask.pocoo.org/docs/1.0/quickstart/#a-minimal-application)，很简单的一段：

```Python
from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello_world():
    return 'Hello, World!'
```

按照官网给出的方式运行：

```shell
$ export FLASK_APP=hello.py
$ flask run
 * Running on http://127.0.0.1:5000/
```

显示已经运行在了本机的5000端口上，至此Flask的环境设置完成，并能正常运行。需要注意的一点是，由于我是在windows环境下进行的开发，所以并不能直接使用`export`命令对环境变量进行设置，不过不用担心，官网已经给出了windows下应该如何设置环境变量的指导：

```Python
If you are on Windows, the environment variable syntax depends on command line interpreter. On Command Prompt:
  C:\path\to\app>set FLASK_APP=hello.py
And on PowerShell:
  PS C:\path\to\app> $env:FLASK_APP = "hello.py"
```

最后补充一点，虽然官网上给出启动Flask的方法是先设置FLASK_APP环境变量，然后再run，但是这样其实并不是很方便，我的做法是直接在源代码最下面加上main函数作为入口：

```Python
if __name__ == "__main__":
    app.run(host='0.0.0.0', port=80)
```

这样直接运行源代码就ok了：

```Shell
D:\github_repos\mnist_service\docker_app\webapp> python app.py

 * Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.
   Use a production WSGI server instead.
 * Debug mode: off
 * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)
```

## 3.2. 路由绑定

Flask的安装已经基本完成了，但是最终项目要实现的功能显然不是hello.py这么简单，因此以及往下看文档，第一个比较重要的部分就是**路由**，这个概念其实很简单，可以直接理解成将**路径**和一个**动作**绑定起来，以官网上给出的代码为例：

```Python
@app.route('/hello')
def hello():
    return 'Hello, World'
```

这一段就是将'/hello'这一路径和hello()函数进行了绑定，这样当用户访问``127.0.0.1:80/hello``时，就会触发`hello()`函数，也就是会返回'Hello， World'这个字符串。理解了这种**绑定**逻辑，那么用路由能实现哪些功能就完全自由了，你可以返回一段字符串、一个特定格式的报文、一个漂亮的网页或者在服务器的后台处理一堆数据等等，至于具体的路由使用文档，[Flask的文档](http://flask.pocoo.org/docs/1.0/quickstart/#a-minimal-application)也写得很详细，一步步follow一遍就基本熟悉了。

## 3.3. 数据交互

基本了解了路由的绑定和使用之后，接下来就要设计核心的后台逻辑了（毕竟本项目没有要求漂亮的网页设计），继续阅读文档，在Flask中，请求作为一个对象被处理，这个对象包含了很多方法和属性，因此也不需要展开了解，文档中给出的例子已经足够我们理解了：

```Python
@app.route('/login', methods=['POST', 'GET'])
def login():
    error = None
    if request.method == 'POST':
        if valid_login(request.form['username'],
                       request.form['password']):
            return log_the_user_in(request.form['username'])
        else:
            error = 'Invalid username/password'
    # the code below is executed if the request method
    # was GET or the credentials were invalid
    return render_template('login.html', error=error)
```

阅读并能适当修改这一段代码，基本上request的一些基本用法就已经ok了，完整的request类中包含的方法和属性可以直接查看[request类的API文档](http://flask.pocoo.org/docs/1.0/api/#incoming-request-data)

## 3.4. 接口调试

最后说一点基于之前网页开发的建议，由于项目中会涉及到文件上传这种操作，所以在调试的过程中肯定需要反复的上传文件或者提交表单，这样如果直接用浏览器来进行调试（比如在Google Chrome中按F12），可能构造测试数据的过程会很复杂，而且也有很多的限制。因此我在调试的过程中用到了[Postman](https://www.getpostman.com/)，这是一个用于接口调试（不仅仅限于网页）的工具，借助Postman可以很容易地构造各种http报文，包括Get、Post方法的选择、提交文件、构造复杂表单、构造http头等等，最后放一张Postman的表单构造器截图，还是很强大的：
![Postman构造表单](https://raw.githubusercontent.com/imdonnie/playground/master/Markdown-Images/Postman构造表单.png)

# 4. Cassandra数据库

## 4.1. 未完成

# 5. Docker学习和使用

## 5.1. 概念理解

如果说对于有一定Python基础的人来说，写出一个简单的Flask应用可能只是一两个小时的事情，那么Docker显然没有这么容易，其中各种概念、逻辑甚至是哲学都可能成为运用Docker的阻碍。
仍然是从[文档](https://docs.docker.com/get-started/)开始。第一部分主要是对Docker的设计目的的介绍，同时也引出了一些基本的概念。引用一段Docker原文的讲解：
> A container is launched by running an image. An image is an executable package that includes everything needed to run an application--the code, a runtime, libraries, environment variables, and configuration files.
> A container is a runtime instance of an image--what the image becomes in memory when executed (that is, an image with state, or a user process). You can see a list of your running containers with the command, docker ps, just as you would in Linux.

理解：image是相对静态的，包含了运行一个app需要的代码和依赖，类似可执行文件和配置文件的集合；当image运行起来时（放入内存时）成为一个container，类似进程。

接着往下看：
>Containerization makes CI/CD seamless. For example:
>
>- applications have no system dependencies
>- updates can be pushed to any part of a distributed application
>- resource density can be optimized.

理解：利用docker的一些好处，应用与操作系统解耦和，便于持续集成和持续发布，优化资源配置。**本项目为了简化生成image的过程，结合DockerHub和GitHub配置了一个简单的持续集成服务，具体实现方法见之后的章节。**

## 5.2. Dockerfile和Container

第二部分继续介绍了一些概念以及这些概念之间的关系做了介绍：
>It’s time to begin building an app the Docker way. We start at the bottom of the hierarchy of such an app, which is a container, which we cover on this page. Above this level is a service, which defines how containers behave in production, covered in Part 3. Finally, at the top level is the stack, defining the interactions of all the services, covered in Part 5.

理解：docker上的应用层次：最底层为container（类似进程），上层为service，定义了container如何工作（part3内容），多个service堆叠成stack，同时stack定义了service之间的交互（part5）。

接着，文档解释了Docker中十分重要的内容：Dockerfile，并且给出了一个简单的Dockerfile样例：
>Dockerfile defines what goes on in the environment inside your container. Access to resources like networking interfaces and disk drives is virtualized inside this environment, which is isolated from the rest of your system, so you need to map ports to the outside world, and be specific about what files you want to “copy in” to that environment. However, after doing that, you can expect that the build of your app defined in this Dockerfile behaves exactly the same wherever it runs.

`Dockerfile`

```Dockerfile
# Use an official Python runtime as a parent image
# 以一个精简版的python-3环境作为parent image（其他的改动都是基于这个镜像之上的）
FROM python:3-slim
# Set the working directory to /app
# 设定 /app 为工作路径
WORKDIR /app
# Copy the current directory contents into the container at /app
# 将当前路径（源代码所在路径）拷贝进container中的 /app路径中
COPY . /app
# Install any needed packages specified in requirements.txt
# 根据requirements.txt中的要求配置环境
RUN pip install --trusted-host pypi.python.org -r requirements.txt
# Make port 80 available to the world outside this container
# 将这个container的80端口暴露出来
EXPOSE 80
# Define environment variable
# 定义一个环境变量，在这段代码中似乎没什么作用，但是之后会用到的
ENV NAME World
# Run app.py when the container launches
# 在container中执行 python app.py 这个命令
CMD ["python", "app.py"]
```

`requirements.txt`

```Plain Text
Flask
Redis
```

理解：在这一阶段要完全理解这一段的写法还是比较困难的，可以结合脚本中的注释（虽然肯定还是有疑问），理解到Dockerfile用于定义container的启动动作，同时定义接口映射等信息，requiremnets.txt用于配置python中需要的库，这样就足够了。

`app.py`

```Python
from flask import Flask
from redis import Redis, RedisError
import os
import socket

# Connect to Redis
redis = Redis(host="redis", db=0, socket_connect_timeout=2, socket_timeout=2)

app = Flask(__name__)

@app.route("/")
def hello():
    try:
        visits = redis.incr("counter")
    except RedisError:
        visits = "<i>cannot connect to Redis, counter disabled</i>"

    html = "<h3>Hello {name}!</h3>" \
           "<b>Hostname:</b> {hostname}<br/>" \
           "<b>Visits:</b> {visits}"
    return html.format(name=os.getenv("NAME", "world"), hostname=socket.gethostname(), visits=visits)

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=80)
```

理解：`app.py`本身没什么太多可说的，主要就是一个测试用例，通读一遍理解清楚就行，正好也回顾了一下第一章对Flask的介绍。

复制完上面这些代码后，就可以按照文档的说明来试着跑一下第一个Docker Container了，首先，类似Linux中的Makefile，Dockerfile是对一堆源代码进行编译的脚本文件，在配置好的Docker环境，可以直接命令行编译运行。

首先确认一下目录中的文件都齐了：

```Shell
$ ls
Dockerfile app.py requirements.txt
```

然后一行命令直接编译：

```Shell
docker build -t friendlyhello .
```

编译完成后运行docker命令看一下：

```Shell
$ docker image ls

REPOSITORY            TAG                 IMAGE ID
friendlyhello         latest              326387cea398
```

看到friendlyhello已经成功编出来，那么Dockerfile这部分就基本ok了，接下来可以继续参考文档，运行一下就行。

## 5.3. 更多Container操作和集群配置

前文已经完成了一个简单的Dockefile的编写，但是明显还有很多问题悬而未决，比如：应该如何调试Container？如果程序运行的环境比较复杂时可以用一个Dockerfile搞定么（比如Python+Tensorflow+Flask+Cassandra...）？不同的Container之间如果同时运行，那么它们之间应该如何交互呢？这些问题可能在这一节无法全部解决，但是这都是要完成项目所无法绕开的。

首先结合Docker的官方文档，可以进一步了解docker-compose.yml：
>A docker-compose.yml file is a YAML file that defines how Docker containers should behave in production.

理解：docker-compose.yml用于控制container应该如何运行，也就是将container包装成service，或者可以叫做**容器编排**，下面是文档中给出的例子：

`docker-compose.yml`

```YAML
version: "3"
services:
  web:
    # replace username/repo:tag with your name and image details
    image: username/repo:tag
    deploy:
      replicas: 5
      resources:
        limits:
          cpus: "0.1"
          memory: 50M
      restart_policy:
        condition: on-failure
    ports:
      - "4000:80"
    networks:
      - webnet
networks:
  webnet:
```

文档中对于这一段docker-compose.yml的解释：
>This docker-compose.yml file tells Docker to do the following:
>Pull the image we uploaded in step 2 from the registry.
>
>- Run 5 instances of that image as a service called web, limiting each one to use, at  most, 10% of the CPU (across all cores), and 50MB of RAM.
>- Immediately restart containers if one fails.
>- Map port 4000 on the host to web’s port 80.
>- Instruct web’s containers to share port 80 via a load-balanced network called webnet. (Internally, the containers themselves publish to web’s port 80 at an ephemeral port.)
>- Define the webnet network with the default settings (which is a load-balanced overlay network).

下面仍然是一段操作指导，直接搬运原文了：

运行步骤：

```Shell
docker swarm init
docker stack deploy -c docker-compose.yml getstartedlab
```

>Our single service stack is running 5 container instances of our deployed image on one host. Let’s investigate.
>Get the service ID for the one service in our application:
`docker service ls`
>Look for output for the web service, prepended with your app name. If you named it the same as shown in this example, the name isgetstartedlab_web. The service ID is listed as well, along with the number of replicas, image name, and exposed ports.
>A single container running in a service is called a task. Tasks are given unique IDs that numerically increment, up to the number of replicas you defined in docker-compose.yml. List the tasks for your service:
`docker service ps getstartedlab_web`
>Tasks also show up if you just list all the containers on your system, though that is not filtered by service:
`docker container ls -q`
>关闭步骤：
>Take the app down with docker stack rm:
`docker stack rm getstartedlab`
>Take down the swarm.
`docker swarm leave --force`

理解：运行状态下的多个概念，stack>service>container(=running image)，or image+Dockerfile=container, container+docker-compose.yml=service
再次强调，Dockerfile定义了image的启动（比如加载依赖，环境变量，运行和编译指令，类似Makefile），YAML定义了一组container的启动（比如资源占用，端口映射，scale设置，负载均衡，类似一个资源调度的配置文件）。

基于项目本身，我们需要的环境主体主要是一个**服务器后端程序（Flask+Tenforslow）** 加上一个 **数据库服务（Cassandra）**，在我的实现过程中，这两部分是很难融合的，也就是说必须在两个Container中分别运行这两部分，并且让它们之间能够正确交互（因为项目中需要从数据库读写数据）。

基于这种需求，我们需要进一步了解Docker中的**容器编排**。

## 5.4. 容器编排

当刚刚写完第一个Dockfile时，对于整个项目还是信心满满的，毕竟已经摸到了Docker门槛的边缘，但是很快就发现了一个残酷的事实，那就是如何把服务器和数据库配置到同一个环境里。我试了以Python做parent image，在上面配Cassandra，也试过以Cassandra为parent image，在上面配置python，但是事实是这些都不是正确的办法，服务器程序和数据库不可能写在同一个Dockerfile中。此时还是官方文档来救了命：
>Create a file called docker-compose.yml in your project directory and paste the following:

```YAML
version: '3'
services:
  web:
    build: .
    ports:
     - "5000:5000"
  redis:
    image: "redis:alpine"
```

看起来似乎只有短短几行，但是其实这就已经完成了单个Container绝对无法做到事情，那就是启动两个相对独立的服务：
>This Compose file defines two services, **web** and **redis**. The web service:
>
> - Uses an image that’s built from the Dockerfile in the current directory.
>
>- Forwards the exposed port 5000 on the container to port 5000 on the host machine. We use the default port for the Flask web server, 5000.
>
>The redis service uses a public Redis image pulled from the Docker Hub registry.

理解：docker-compose.yml定义了两个service（其实就是两个container，但是同时带有一些配置）的启动方式，以及它们的启动顺序，以此我们可以再进一步理解container，虽然container是很完整的runtime，甚至是os，但是还是应该将其视为一个进程比较好，最终打包发布出来的**服务**不是某一个单一的container，而是**一堆container**的协作。类比本机的开发环境，一个Web服务器上可能需要运行Node.js、Apache、MySQL等等，着每一个服务在Docker的逻辑中就应该由一个Container来实现。

具体的容器编排还会涉及网络、环境配置等等，因此还是需要阅读[Compose官方文档的相关章节](https://docs.docker.com/compose/gettingstarted/)，在此就不再赘述了。

## 5.5. 在Docker中调试

这部分并不是项目开发所必备的东西，但是却是很有帮助也很有意思的一部分。在容器的编排和运行的过程中，有时会有一种**失控**的感觉，因为一旦容器开始运行，那么就不像普通的本地程序那样容易debug、查看log、进行各种测试，或者修改一小段代码再重新运行。

这些便利是一个**开发环境**所能提供的，但是Docker可能更多的是一个**生产环境**，也就是说我们**似乎应该**在一个开发环境下把代码和相关配置等等全部调通，然后再书写合适的Dockerfile，并进行容器编排以及打包发布。

但是**事实上**，Docker同样可以用来开发和调试。关于**应用开发**，Docker官方文档给出了一些[介绍](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/)，此处我仅简述一下在项目中实际使用的过程。

在Container中进行app和Cassandra联调的时候，我遇到了很多很多的问题，尤其是container之间的交互失败。通过docker-compose拉起两个容器之后，通过外部的接口测试工具（比如postman）来访问接口出现失败，但是报错的信息往往过于笼统，比如**数据库连接失败**，这个信息可能由很多原因导致，比如数据库没有正常运行，或者容器之间的端口暴露不正确，或者是app中连接数据库的代码出错，如果这是在本机环境中，问题的定位当然简单很多，毕竟只需改改代码或者配置文件然后重新跑就行了，但是在容器中要如何调试呢？答案就是**进入容器**。

[这篇博文](https://www.cnblogs.com/xhyan/p/6593075.html)给出了进入容器的一些方法，我主要使用的是`docker exec/run -iter [container/image] bash`的方式进入容器：

```Batch
PS D:\github_repos\mnist_service> docker run -iter friendlyhello bash
root@be88cc4e596c:/app#
```

可以看到这样一行命令其实是启动了`friendlyhello`这个image，并且执行了`bash`命令（而没有像Dockerfile中设定的那样执行 `python app.py`），那么我们进入的这个container有些啥呢？

```Batch
root@be88cc4e596c:/app# ls
Dockerfile  app.py  requirements.txt
```

再退回上一级看看有啥：

```Batch
root@be88cc4e596c:/app# cd ..
root@be88cc4e596c:/# ls
app  bin  boot  dev  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var
```

是不是很眼熟，基本就是一个**微缩版**的linux环境，而其中我们的workspace自然就是`/app`了，还记得之前的那个Dockerfile中的语句么：

```Dockerfile
...
# Set the working directory to /app
WORKDIR /app
# Copy the current directory contents into the container at /app
COPY . /app
...
```

现在这两句话的意义就好理解多了，WORKDIR是当容器运行时的工作路径，COPY语句是把编译时Dockerfile所在的路径整个拷贝进container中的